{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Election Integrity Author Interactions\n",
    "\n",
    "**Objective:** This notebook identifies all tweets removed by Twitter in its election integrity-related takedowns that mentioned, replied, or retweeted to a certain Twitter account. \n",
    "\n",
    "**Prerequisites:** \n",
    "- In the same directory as this notebook, there must be a folder called \"dataSources\" with all of the csvs of tweet accounts removed by Twitter. These are listed below and can be found [here](https://about.twitter.com/en_us/values/elections-integrity.html#data). \n",
    "- You should also know the userid of the account of interest. If you know the account handle, the userid can be found [here](http://gettwitterid.com).\n",
    "\n",
    "**Outcomes:** After running this notebook, there should be a folder called \"foundAuthorInteractions\" containing a csv for each on in the dataSources folder. Each of the output csvs contains all tweets that mention, are replies to, or retweet the provided Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointers to all locations of the files of interest\n",
    "filenames = ['dataSources/ira_tweets_csv_hashed.csv',\n",
    "             'dataSources/iranian_tweets_csv_hashed.csv',\n",
    "             'dataSources/russia_201901_1_tweets_csv_hashed.csv',\n",
    "             'dataSources/iran_201901_1_tweets_csv_hashed.csv',\n",
    "             'dataSources/venezuela_201901_1_tweets_csv_hashed.csv',\n",
    "             'dataSources/venezuela_201901_2_tweets_csv_hashed.csv',\n",
    "             'dataSources/bangladesh_201901_1_tweets_csv_hashed.csv'\n",
    "            ]\n",
    "\n",
    "# The account id of the user you're interested in (default is @nytimes)\n",
    "account_id = '807095'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of necessary libraries\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder for saving author interactions csvs\n",
    "os.mkdir('foundAuthorInteractions_'+str(account_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing dataSources/ira_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Read 1000000 rows so far\n",
      "Read 2000000 rows so far\n",
      "Read 3000000 rows so far\n",
      "Read 4000000 rows so far\n",
      "Read 5000000 rows so far\n",
      "Read 6000000 rows so far\n",
      "Read 7000000 rows so far\n",
      "Read 8000000 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/iranian_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Read 1000000 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/russia_201901_1_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/iran_201901_1_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Read 1000000 rows so far\n",
      "Read 2000000 rows so far\n",
      "Read 3000000 rows so far\n",
      "Read 4000000 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/venezuela_201901_1_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Read 1000000 rows so far\n",
      "Read 2000000 rows so far\n",
      "Read 3000000 rows so far\n",
      "Read 4000000 rows so far\n",
      "Read 5000000 rows so far\n",
      "Read 6000000 rows so far\n",
      "Read 7000000 rows so far\n",
      "Read 8000000 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/venezuela_201901_2_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Finished this data source!\n",
      "Currently processing dataSources/bangladesh_201901_1_tweets_csv_hashed.csv...\n",
      "Read 0 rows so far\n",
      "Finished this data source!\n"
     ]
    }
   ],
   "source": [
    "# Check all datasets for \n",
    "for i in range(0, len(filenames)):\n",
    "    # Update user on progress\n",
    "    print(\"Currently processing \" + filenames[i] + \"...\")\n",
    "\n",
    "    # Open csv of focus\n",
    "    with open(filenames[i]) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter = ',')\n",
    "\n",
    "        # Set up a counter to later update user on progress\n",
    "        count = 0 \n",
    "\n",
    "        # Instantiate for later use\n",
    "        in_reply_to_userid_index = 0\n",
    "        retweet_userid_index = 0\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # Check every row for interactions with the user\n",
    "        for row in readCSV:\n",
    "            \n",
    "            # Set up dataframe for holding data\n",
    "            if(count == 0):\n",
    "                df = pd.DataFrame(columns = row)\n",
    "                \n",
    "                # Get the index of the columns of our interest\n",
    "                in_reply_to_userid_index = row.index('in_reply_to_userid')\n",
    "                retweet_userid_index = row.index('retweet_userid')\n",
    "                \n",
    "            elif ((row[in_reply_to_userid_index] == account_id) or (row[retweet_userid_index] == account_id)):\n",
    "                df = df.append([pd.DataFrame(columns=list(df), data=[row])])\n",
    "                \n",
    "            if(count % 1000000 == 0):\n",
    "                print(\"Read \" + str(count) + \" rows so far\")\n",
    "                \n",
    "            count += 1\n",
    "                    \n",
    "        # Save as csv\n",
    "        df.to_csv('foundAuthorInteractions_'+str(account_id)+'/'+filenames[i][12:len(filenames[i])-4]+'AuthorInteractions.csv')\n",
    "    \n",
    "    print('Finished this data source!')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
